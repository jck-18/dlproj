{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06a36a9",
   "metadata": {},
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b8efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\KEVIN\\AppData\\Local\\Temp\\ipykernel_28712\\1969151095.py:6: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df = pd.read_csv(\"D:\\dlproject\\dlproj\\data\\processed\\processed_essays.csv\")  # Replace with your actual file\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7449c6e96024074b1c47de5dd96c3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KEVIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\KEVIN\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a65bdace674dfaac402ae78175798f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfefe81c5644434b93986786403fe075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e72438801d94350a9ceeb375d46b195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KEVIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"D:\\dlproject\\dlproj\\data\\processed\\processed_essays.csv\")  # Replace with your actual file\n",
    "essays = df['clean_essay'].astype(str).tolist()\n",
    "scores = df['domain1_score'].tolist()\n",
    "\n",
    "# Train-test split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(essays, scores, test_size=0.1)\n",
    "\n",
    "# Tokenize\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c4211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class EssayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "train_dataset = EssayDataset(train_encodings, train_labels)\n",
    "val_dataset = EssayDataset(val_encodings, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea2ffba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de8688179bf4b98b75cd255319b0bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff939b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\KEVIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KEVIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c660fa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c43da5846548b485d9ba44855af8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 41.6355, 'grad_norm': 10.494009017944336, 'learning_rate': 4.785958904109589e-05, 'epoch': 0.17}\n",
      "{'loss': 25.0813, 'grad_norm': 31.94352149963379, 'learning_rate': 4.571917808219178e-05, 'epoch': 0.34}\n",
      "{'loss': 14.7982, 'grad_norm': 16.629671096801758, 'learning_rate': 4.357876712328767e-05, 'epoch': 0.51}\n",
      "{'loss': 12.1791, 'grad_norm': 109.85242462158203, 'learning_rate': 4.143835616438356e-05, 'epoch': 0.68}\n",
      "{'loss': 8.0709, 'grad_norm': 423.0643310546875, 'learning_rate': 3.929794520547945e-05, 'epoch': 0.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db90359afe244669d80c65cb75a28d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.415451526641846, 'eval_runtime': 20.8794, 'eval_samples_per_second': 62.167, 'eval_steps_per_second': 15.566, 'epoch': 1.0}\n",
      "{'loss': 6.6905, 'grad_norm': 11.692829132080078, 'learning_rate': 3.715753424657534e-05, 'epoch': 1.03}\n",
      "{'loss': 5.8205, 'grad_norm': 59.30990982055664, 'learning_rate': 3.501712328767123e-05, 'epoch': 1.2}\n",
      "{'loss': 7.9913, 'grad_norm': 46.59178161621094, 'learning_rate': 3.287671232876712e-05, 'epoch': 1.37}\n",
      "{'loss': 6.6568, 'grad_norm': 100.25692749023438, 'learning_rate': 3.073630136986301e-05, 'epoch': 1.54}\n",
      "{'loss': 4.3876, 'grad_norm': 24.671932220458984, 'learning_rate': 2.8595890410958903e-05, 'epoch': 1.71}\n",
      "{'loss': 6.7983, 'grad_norm': 487.3072509765625, 'learning_rate': 2.6455479452054793e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad497fc539343ff821bc8e3e8fe4814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.352356910705566, 'eval_runtime': 21.2377, 'eval_samples_per_second': 61.118, 'eval_steps_per_second': 15.303, 'epoch': 2.0}\n",
      "{'loss': 6.3502, 'grad_norm': 413.0533142089844, 'learning_rate': 2.4315068493150686e-05, 'epoch': 2.05}\n",
      "{'loss': 5.1171, 'grad_norm': 22.599058151245117, 'learning_rate': 2.2174657534246575e-05, 'epoch': 2.23}\n",
      "{'loss': 4.2669, 'grad_norm': 177.41375732421875, 'learning_rate': 2.0034246575342465e-05, 'epoch': 2.4}\n",
      "{'loss': 3.268, 'grad_norm': 46.62345504760742, 'learning_rate': 1.7893835616438355e-05, 'epoch': 2.57}\n",
      "{'loss': 3.2224, 'grad_norm': 35.98884963989258, 'learning_rate': 1.5753424657534248e-05, 'epoch': 2.74}\n",
      "{'loss': 3.9927, 'grad_norm': 130.64639282226562, 'learning_rate': 1.3613013698630136e-05, 'epoch': 2.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c847031f750f41c59dcc04ddf8f265fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.62291955947876, 'eval_runtime': 21.1466, 'eval_samples_per_second': 61.381, 'eval_steps_per_second': 15.369, 'epoch': 3.0}\n",
      "{'loss': 3.8675, 'grad_norm': 13.521726608276367, 'learning_rate': 1.1472602739726027e-05, 'epoch': 3.08}\n",
      "{'loss': 3.3283, 'grad_norm': 24.15824317932129, 'learning_rate': 9.332191780821919e-06, 'epoch': 3.25}\n",
      "{'loss': 2.5954, 'grad_norm': 18.43943214416504, 'learning_rate': 7.191780821917809e-06, 'epoch': 3.42}\n",
      "{'loss': 3.3302, 'grad_norm': 312.2174987792969, 'learning_rate': 5.051369863013699e-06, 'epoch': 3.6}\n",
      "{'loss': 2.6967, 'grad_norm': 17.25446128845215, 'learning_rate': 2.910958904109589e-06, 'epoch': 3.77}\n",
      "{'loss': 2.6906, 'grad_norm': 40.00421142578125, 'learning_rate': 7.705479452054794e-07, 'epoch': 3.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199b9ef0d36043398685776519b79dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.496140480041504, 'eval_runtime': 21.0821, 'eval_samples_per_second': 61.569, 'eval_steps_per_second': 15.416, 'epoch': 4.0}\n",
      "{'train_runtime': 3227.0557, 'train_samples_per_second': 14.475, 'train_steps_per_second': 3.619, 'train_loss': 7.966116322556587, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11680, training_loss=7.966116322556587, metrics={'train_runtime': 3227.0557, 'train_samples_per_second': 14.475, 'train_steps_per_second': 3.619, 'total_flos': 1.2290333267042304e+16, 'train_loss': 7.966116322556587, 'epoch': 4.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118bfe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"model_weights.pkl\")\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load(\"model_weights.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
